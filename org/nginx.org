#+OPTIONS: "\n:t"

* proxy_set_header
配置如下：
#+begin_example
    upstream search_server {
        server 10.0.64.244:8080;
    }
    server {
        listen       8000;
        location / {
           #proxy_set_header Host $host;
           proxy_pass http://search_server;
        }
    }
#+end_example
请求http://localhost:8000
抓包：
#+begin_example
GET / HTTP/1.0
Host: search_server
Connection: close
#+end_example
发现HTTP报文头中Host是search_server。

把proxy_set_header Host $host;前的注释去掉后。
再请求：
#+begin_example
GET / HTTP/1.0
Host: localhost
Connection: close
#+end_example

* source code
  http配置块解释
  ngx_http_block

** 匹配location
   ngx_http_core_find_location

** data link
ngx_connection_t.data -> ngx_http_connection_t
** log
   nginx多进程写日志，为什么没有发生冲突
   nginx所做的操作只是使用O_APPEND方式打开文件。

对于unix系统：
On a Unix and equivalent systems if the file you are writing to was opened with the O_APPEND flag, writes are guaranteed to be atomic regardless of size, unless the file is a pipe or FIFO, in which case atomicity is guaranteed only if the write size is PIPE_BUF or fewer bytes in length. So sayeth the Single Unix Specification on the write system call:

If the O_APPEND flag of the file status flags is set, the file offset shall be set to the end of the file prior to each write and no intervening file modification operation shall occur between changing the file offset and the write operation....

Write requests to a pipe or FIFO shall be handled in the same way as a regular file with the following exceptions: ... Write requests of PIPE_BUF bytes or less shall not be interleaved with data from other processes doing writes on the same pipe. Writes of greater than PIPE_BUF bytes may have data interleaved, on arbitrary boundaries, with writes by other processes, whether or not the O_NONBLOCK flag of the file status flags is set. 

On most Linux systems, PIPE_BUF is 4096. 

linux man手册中：
If the file was open(2)ed with O_APPEND, the file offset is first set to the end of the file before writing.
The adjustment of the file offset and the write operation are performed as an atomic step.

* cache
  可以使用proxy_cache 缓存静态资源
  使用fastcgi_cache 缓存fastcgi请求的应答
* DDOS
* gzip 问题
  nginx 后端的server，在nginx开启gzip的情况下，不能再开启gzip压缩。
  比如同时开启nginx和其后端的tomcat的gzip压缩的支持，
  当tomcat收到HTTP请求时发现Accept-Encoding: gzip, deflate，终端支持gzip压缩，
  于是将返回内容进行压缩。
  当tomcat的reponse被nginx接收时，nginx ngx_http_gzip_filter_module也检测到该请求对应终端支持压缩，
  于是再压缩一边，再将数据发送到终端。

  终端接收到压缩两遍的数据，无法正常使用。
